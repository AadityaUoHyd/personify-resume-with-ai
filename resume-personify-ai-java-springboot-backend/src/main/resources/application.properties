spring.application.name=resume-personify-ai-java-springboot-backend
spring.port=8080

#I've installed "deepseek-r1:8b" on ollama, locally in my laptop. (can be used docker as well to install models.)
#spring.ai.ollama.chat.model=deepseek-r1:8b

#Let's use MISTRAL AI through api-key access. <provide your own mistral API-KEY and CHAT-MODEL using dotenv file>
spring.ai.mistralai.api-key=${MISTRAL_AI_API_KEY}
spring.ai.mistralai.chat.options.model=${MISTRAL_AI_CHAT_MODEL}
